{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b45297d",
   "metadata": {
    "id": "6b45297d"
   },
   "source": [
    "# NSL_KDD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00632d0",
   "metadata": {
    "id": "d00632d0"
   },
   "source": [
    "# libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041a3af",
   "metadata": {
    "id": "c041a3af"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import normalize, minmax_scale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns',None)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4bb0c",
   "metadata": {
    "id": "a1f4bb0c"
   },
   "source": [
    "# DATA IMPORTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d45ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "e36d45ca",
    "outputId": "39736e85-9956-4c51-e8e6-df80e49774ff"
   },
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "train=pd.read_csv('data/KDDTrain+.txt')\n",
    "train.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2834a49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "d2834a49",
    "outputId": "fe849632-5981-4839-bd66-43497fff4ae1"
   },
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "test=pd.read_csv('data/KDDTest+.txt')\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb920b8",
   "metadata": {
    "id": "6bb920b8"
   },
   "source": [
    "## Analysing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd4af9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eecd4af9",
    "outputId": "2f626dbf-5728-4438-8326-a29198d1ad62"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b118f13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b118f13",
    "outputId": "3d54f7ad-ade8-4533-9726-c198542bf7c0"
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83431cd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "83431cd6",
    "outputId": "f358c3a9-c0f7-4cbd-8bef-9af95ecf1ed6"
   },
   "outputs": [],
   "source": [
    "train.describe().style.background_gradient(cmap='Blues').set_properties(**{'font-family':'Segoe UI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17a3c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec17a3c8",
    "outputId": "ff24aa62-f326-4bef-d55b-03a8c682d260"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8672931",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8672931",
    "outputId": "21f307a7-83be-4d3d-dda0-3d06fc6264b1"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db47da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37db47da",
    "outputId": "772e6919-bf5f-4a73-9e3b-f2d75174ebe2"
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f843fde",
   "metadata": {
    "id": "9f843fde"
   },
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ab73e",
   "metadata": {
    "id": "be0ab73e"
   },
   "source": [
    "# Data cleaning\n",
    "columns treatments(add,delete,modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab35a87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "bab35a87",
    "outputId": "41c58577-81d9-4385-b941-6a4cfefa8f15"
   },
   "outputs": [],
   "source": [
    "# #removing the last column\n",
    "train=train.iloc[:,0:42]\n",
    "\n",
    "#naming the attributes\n",
    "train.columns=['duration','protocol_type','service','flag','src_bytes','dst_bytes','land'\n",
    "                                        ,'wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised',\n",
    "                                      'root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files',\n",
    "                                     'num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate',\n",
    "                                       'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n",
    "                                      'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',\n",
    "                                     'dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate',\n",
    "                                     'dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate',\n",
    "                                      'dst_host_srv_rerror_rate','label']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5389879",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "b5389879",
    "outputId": "a13e1d8b-f796-4b0e-a186-7fc9c3f4d2e8"
   },
   "outputs": [],
   "source": [
    "# #removing the last column\n",
    "test=test.iloc[:,0:42]\n",
    "\n",
    "#naming the attributes\n",
    "test.columns=['duration','protocol_type','service','flag','src_bytes','dst_bytes','land'\n",
    "                                        ,'wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised',\n",
    "                                      'root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files',\n",
    "                                     'num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate',\n",
    "                                       'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n",
    "                                      'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',\n",
    "                                     'dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate',\n",
    "                                     'dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate',\n",
    "                                      'dst_host_srv_rerror_rate','label']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e740c1",
   "metadata": {
    "id": "92e740c1"
   },
   "source": [
    "# Preprocessing\n",
    "classification binaire(dos=1,>dos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008a68f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c008a68f",
    "outputId": "d699982b-79b6-434a-f3e0-66a8c37ac63e"
   },
   "outputs": [],
   "source": [
    "print('Training set:')\n",
    "for col_name in train.columns:\n",
    "    if train[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(train[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88100616",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88100616",
    "outputId": "9621406b-c4e1-4380-f385-efc8a1800c8f"
   },
   "outputs": [],
   "source": [
    "print('Testing set:')\n",
    "for col_name in test.columns:\n",
    "    if test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3df684",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e3df684",
    "outputId": "a1fd9741-2bce-4ec2-a516-d90ea141e6e2"
   },
   "outputs": [],
   "source": [
    "#print(train['service'].count_values())\n",
    "if test['service'].dtypes == 'object' :\n",
    " unique_cat = test['service'].unique()   \n",
    " print(unique_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49fc32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d49fc32",
    "outputId": "28b4137a-2630-4849-9678-02e7d9f2bffb"
   },
   "outputs": [],
   "source": [
    "#print(train['service'].count_values())\n",
    "if train['service'].dtypes == 'object' :\n",
    " unique_cat = train['service'].unique()   \n",
    " print(unique_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7c6ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8ac7c6ab",
    "outputId": "c4bc0c8a-e221-42bd-b941-4118f719b746"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,40))\n",
    "sns.countplot(palette='mako', y='service' , data=train, order = train['service'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc603a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bbc603a",
    "outputId": "26b01009-b69b-4bd2-800f-5f61735adc72"
   },
   "outputs": [],
   "source": [
    "if train['flag'].dtypes == 'object' :\n",
    " unique_cat = train['flag'].unique()   \n",
    " print(unique_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22294336",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "22294336",
    "outputId": "e463e6ab-32bc-4709-fff4-b9951ec1a7bc"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=train['flag'].value_counts().index, y=train['flag'].value_counts(), palette='CMRmap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba882f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ba882f5",
    "outputId": "77bad3be-3168-4833-f703-504a000498e3"
   },
   "outputs": [],
   "source": [
    "if train['protocol_type'].dtypes == 'object' :\n",
    " unique_cat = train['protocol_type'].unique()   \n",
    " print(unique_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbda57b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "0bbda57b",
    "outputId": "163059d2-c8bc-49a6-cc77-01c6009eb013"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=train['protocol_type'].value_counts().index, y=train['protocol_type'].value_counts(), palette='CMRmap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd6abe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ddd6abe",
    "outputId": "336cd212-29bd-465c-c194-a5bd9451e330"
   },
   "outputs": [],
   "source": [
    "if train['label'].dtypes == 'object' :\n",
    " unique_cat = train['label'].unique()   \n",
    " print(unique_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edc2fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31edc2fe",
    "outputId": "a87954c0-c833-4d1c-ca50-e5ee46b57b1a"
   },
   "outputs": [],
   "source": [
    "if test['label'].dtypes == 'object' :\n",
    " unique_cat = test['label'].unique()   \n",
    " print(unique_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e04a8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08e04a8e",
    "outputId": "07ff44c4-aa8a-4e67-e2e0-028972aaa9cd"
   },
   "outputs": [],
   "source": [
    "set1 = {'normal' ,'neptune' ,'warezclient', 'ipsweep', 'portsweep', 'teardrop', 'nmap',\n",
    " 'satan', 'smurf' ,'pod', 'back' ,'guess_passwd', 'ftp_write' ,'multihop',\n",
    " 'rootkit' ,'buffer_overflow', 'imap' ,'warezmaster' ,'phf' ,'land',\n",
    " 'loadmodule' ,'spy' ,'perl'}\n",
    "set2 = {'neptune' ,'normal' ,'saint', 'mscan', 'guess_passwd', 'smurf', 'apache2',\n",
    " 'satan' ,'buffer_overflow', 'back', 'warezmaster' ,'snmpgetattack',\n",
    " 'processtable', 'pod', 'httptunnel', 'nmap' ,'ps' ,'snmpguess' ,'ipsweep',\n",
    " 'mailbomb', 'portsweep', 'multihop', 'named', 'sendmail', 'loadmodule' ,'xterm',\n",
    " 'worm' ,'teardrop', 'rootkit', 'xlock' ,'perl', 'land' ,'xsnoop', 'sqlattack',\n",
    " 'ftp_write' ,'imap', 'udpstorm', 'phf'}\n",
    "set3 = set1.union(set2)\n",
    "print(set3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebbf12d",
   "metadata": {
    "id": "6ebbf12d"
   },
   "source": [
    "# 1-N Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0a6e3",
   "metadata": {
    "id": "d0e0a6e3"
   },
   "outputs": [],
   "source": [
    "train['protocol_type'].replace({ 'udp' : 0, 'tcp' : 1 ,'icmp': 2 },inplace = True)\n",
    "train['flag'].replace({ 'OTH' : 0, 'REJ' : 1 ,'RSTO': 2 ,'RSTOS0':3 ,'RSTR': 4,'S0':5,\n",
    "                           'S1':6,'S2':7, 'S3':8, 'SF':9,'SH':10 },inplace = True)\n",
    "train['service'].replace({ 'other':0,'private':1,'http':2,'remote_job':3,'ftp_data':4,'name':5,'netbios_ns':6,'eco_i':7,'mtp':8,\n",
    "    'telnet':9,'finger':10,'domain_u':11,'supdup':12, 'uucp_path':13,'Z39_50':14,'smtp':15,'csnet_ns':16,'uucp':17,'netbios_dgm':18,'urp_i':19,\n",
    "    'auth':20,'domain':21,'ftp':22,'bgp':23,'ldap':24,'ecr_i':25,'gopher':26, 'vmnet':27,'systat':28,'http_443':29,\n",
    "    'efs':30,'whois':31,'imap4':32,'iso_tsap':33,'echo':34,'klogin':35,'link':36,'sunrpc':37,'login':38,'kshell':39,\n",
    "    'sql_net':40,'time':41,'hostnames':42,'exec':43,'ntp_u':44,'discard':45,'nntp':46,'courier':47,'ctf':48,'ssh':49,\n",
    "    'daytime':50,'shell':51,'netstat':52,'pop_3':53,'nnsp':54,'IRC':55,'pop_2':56,'printer':57,'tim_i':58,'pm_dump':59,'red_i':60,\n",
    "    'netbios_ssn':61,'rje':62,'X11':63,'urh_i':64,'http_8001':65,'aol':66,'http_2784':67,'tftp_u':68,'harvest':69},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fb500",
   "metadata": {
    "id": "c05fb500"
   },
   "outputs": [],
   "source": [
    "test['protocol_type'].replace({ 'udp' : 0, 'tcp' : 1 ,'icmp': 2 },inplace = True)\n",
    "test['flag'].replace({ 'OTH' : 0, 'REJ' : 1 ,'RSTO': 2 ,'RSTOS0':3 ,'RSTR': 4,'S0':5,\n",
    "                           'S1':6,'S2':7, 'S3':8, 'SF':9,'SH':10 },inplace = True)\n",
    "test['service'].replace({ 'other':0,'private':1,'http':2,'remote_job':3,'ftp_data':4,'name':5,'netbios_ns':6,'eco_i':7,'mtp':8,\n",
    "    'telnet':9,'finger':10,'domain_u':11,'supdup':12, 'uucp_path':13,'Z39_50':14,'smtp':15,'csnet_ns':16,'uucp':17,'netbios_dgm':18,'urp_i':19,\n",
    "    'auth':20,'domain':21,'ftp':22,'bgp':23,'ldap':24,'ecr_i':25,'gopher':26, 'vmnet':27,'systat':28,'http_443':29,\n",
    "    'efs':30,'whois':31,'imap4':32,'iso_tsap':33,'echo':34,'klogin':35,'link':36,'sunrpc':37,'login':38,'kshell':39,\n",
    "    'sql_net':40,'time':41,'hostnames':42,'exec':43,'ntp_u':44,'discard':45,'nntp':46,'courier':47,'ctf':48,'ssh':49,\n",
    "    'daytime':50,'shell':51,'netstat':52,'pop_3':53,'nnsp':54,'IRC':55,'pop_2':56,'printer':57,'tim_i':58,'pm_dump':59,'red_i':60,\n",
    "    'netbios_ssn':61,'rje':62,'X11':63,'urh_i':64,'http_8001':65,'aol':66,'http_2784':67,'tftp_u':68,'harvest':69},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b98ff6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "id": "94b98ff6",
    "outputId": "a20590d9-c4f3-4092-f185-5c6d90412477"
   },
   "outputs": [],
   "source": [
    "# train['label'].replace({ 'teardrop':1, 'back':1, 'smurf':1, 'udpstorm':1, 'apache2':1, 'pod':1, 'land':1, 'mailbomb':1, 'processtable':1, 'nmap':1,                                           \n",
    "#   'phf':0, 'xsnoop':0, 'worm':0, 'satan':0, 'buffer_overflow':0, 'named':0, 'perl':0, 'saint':0, 'guess_passwd':0,\n",
    "# 'ipsweep':0, 'multihop':0, 'imap':0, 'mscan':0, 'loadmodule':0, 'ftp_write':0, 'rootkit':0, 'snmpguess':0, 'sendmail':0, 'warezmaster':0,\n",
    "#     'normal':0, 'portsweep':0, 'snmpgetattack':0, 'sqlattack':0, 'httptunnel':0, 'ps':0, 'spy':0, 'xterm':0, 'warezclient':0,\n",
    "#       'neptune':1  },inplace = True)\n",
    "\n",
    "train['label'].replace({ \n",
    "'sendmail':0, 'mailbomb':0, 'imap':0, 'neptune':1, 'rootkit':0, 'back':0, 'udpstorm':1, 'phf':0, 'ftp_write':0,\n",
    "'guess_passwd':0, 'pod':1, 'mscan':0, 'land':1, 'teardrop':1, 'sqlattack':0, 'named':0, 'warezmaster':0, 'multihop':0, 'loadmodule':0, \n",
    "'ps':0, 'warezclient':0, 'worm':0, 'snmpgetattack':0, 'httptunnel':0, 'portsweep':0, 'normal':0, 'perl':0, 'buffer_overflow':0, 'xlock':0, \n",
    "'ipsweep':0, 'apache2':1, 'processtable':0, 'xterm':0, 'spy':0, 'snmpguess':0, 'nmap':0, 'smurf':1, 'saint':1, 'xsnoop':0, 'satan':0\n",
    "  },inplace = True)\n",
    "\n",
    "\n",
    "test['label'].replace({ \n",
    "'sendmail':0, 'mailbomb':0, 'imap':0, 'neptune':1, 'rootkit':0, 'back':0, 'udpstorm':1, 'phf':0, 'ftp_write':0,\n",
    "'guess_passwd':0, 'pod':1, 'mscan':0, 'land':1, 'teardrop':1, 'sqlattack':0, 'named':0, 'warezmaster':0, 'multihop':0, 'loadmodule':0, \n",
    "'ps':0, 'warezclient':0, 'worm':0, 'snmpgetattack':0, 'httptunnel':0, 'portsweep':0, 'normal':0, 'perl':0, 'buffer_overflow':0, 'xlock':0, \n",
    "'ipsweep':0, 'apache2':1, 'processtable':0, 'xterm':0, 'spy':0, 'snmpguess':0, 'nmap':0, 'smurf':1, 'saint':1, 'xsnoop':0, 'satan':0\n",
    "  },inplace = True)\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edccd5e",
   "metadata": {
    "id": "1edccd5e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6a668",
   "metadata": {
    "id": "b1b6a668"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0ad4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35a0ad4b",
    "outputId": "2d81b5f1-3132-44f2-fd64-8dbc6f64bce7"
   },
   "outputs": [],
   "source": [
    "counts = train[\"service\"].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abad53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2abad53",
    "outputId": "a8e4e35f-e31d-4b53-d44d-32310e761cae"
   },
   "outputs": [],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc1a13",
   "metadata": {
    "id": "4afc1a13"
   },
   "source": [
    "Balancing the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae8042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fae8042",
    "outputId": "463c0222-64b4-4075-8dba-efbac35e8d9a"
   },
   "outputs": [],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c0a98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "395c0a98",
    "outputId": "f8165980-f507-4561-bc77-bae7ab27cf72"
   },
   "outputs": [],
   "source": [
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475da87f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "475da87f",
    "outputId": "989c8823-aa8d-44a4-deef-67aaef4e3b63"
   },
   "outputs": [],
   "source": [
    "#before balancing the label\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the distribution of the 'label' column before balancing\n",
    "train['label'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels (Before Balancing)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacb056",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cacb056",
    "outputId": "cd7da3f8-06f3-4e27-b67b-43d1131a5f24"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = train[train['label'] == 0]\n",
    "df_minority = train[train['label'] == 1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=len(df_majority),    \n",
    "                                 random_state=123)\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "train = df_upsampled\n",
    "\n",
    "# Display new class counts\n",
    "train['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919e867",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "f919e867",
    "outputId": "8edde9a9-14e5-4000-e836-9e8ed855dcb8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# count the number of each label value in the balanced dataset\n",
    "label_counts = train['label'].value_counts()\n",
    "\n",
    "# plot a bar chart to show the label count\n",
    "plt.bar(label_counts.index, label_counts.values)\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['dos', '>dos'])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80178c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "8f80178c",
    "outputId": "dbe00a13-a203-4620-d361-d882d7d9abaf"
   },
   "outputs": [],
   "source": [
    "#balancing the test dataset\n",
    "#before balancing the label\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the distribution of the 'label' column before balancing\n",
    "test['label'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels (Before Balancing)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9afa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29e9afa3",
    "outputId": "c9ff7ef3-12ec-4c99-b17b-2c09dc92acda"
   },
   "outputs": [],
   "source": [
    "#balancing the test dataset\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = test[test['label'] == 0]\n",
    "df_minority = test[test['label'] == 1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=len(df_majority),    \n",
    "                                 random_state=123)\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "test = df_upsampled\n",
    "\n",
    "# Display new class counts\n",
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6665e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "d9c6665e",
    "outputId": "ac593a2e-b038-488d-ad11-50e8190d936c"
   },
   "outputs": [],
   "source": [
    "#balancing the test dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# count the number of each label value in the balanced dataset\n",
    "label_counts = train['label'].value_counts()\n",
    "\n",
    "# plot a bar chart to show the label count\n",
    "plt.bar(label_counts.index, label_counts.values)\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['dos', '>dos'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c69ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "4a1c69ee",
    "outputId": "bf7e161d-21c4-4331-d2f0-875d02ea03ac"
   },
   "outputs": [],
   "source": [
    "#apres encoding \n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(train.corr(), annot= True,cmap='mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3420d6",
   "metadata": {
    "id": "8d3420d6"
   },
   "source": [
    "Separate features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2219a4d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2219a4d3",
    "outputId": "ea0031bd-41c9-4278-fc7c-31bcc27d5229"
   },
   "outputs": [],
   "source": [
    "y_train = train.iloc[:, -1]  # select the last column (label) as y_train\n",
    "x_train = train.iloc[:, :-1]  # select all columns except the last one as x_train\n",
    "\n",
    "y_test = test.iloc[:, -1]  # select the last column (label) as y_test\n",
    "x_test = test.iloc[:, :-1]  # select all columns except the last one as x_test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8211a",
   "metadata": {
    "id": "16f8211a"
   },
   "source": [
    "# training the model\n",
    "Train data with one or more chosen classification algorithms (DecisionTrees, SVM, KNN, Naive bayes, Logistic regression ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6a744",
   "metadata": {
    "id": "39b6a744"
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5d4c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62c5d4c4",
    "outputId": "9f577755-b12e-4081-80d7-4e6d9e529808"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier( random_state=88)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "predicted = dt.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy1 = accuracy_score(y_test,predicted)\n",
    "precision1 = precision_score(y_test,predicted)\n",
    "recall1 = recall_score(y_test,predicted)\n",
    "f1_1 = f1_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy1,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84049b8",
   "metadata": {
    "id": "b84049b8"
   },
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0dfc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0db0dfc7",
    "outputId": "00e38611-373c-4c92-b12f-87c5917fb263"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# Fit the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=88)\n",
    "model.fit(x_train, y_train)\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy2 = accuracy_score(y_test,y_pred)\n",
    "precision2 = precision_score(y_test,y_pred)\n",
    "recall2 = recall_score(y_test,y_pred)\n",
    "f1_2 = f1_score(y_test,y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy score: \", accuracy2)\n",
    "print(\"Confusion matrix: \\n\", conf_mat)\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96007184",
   "metadata": {
    "id": "96007184"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764796c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "764796c8",
    "outputId": "7e01b81f-b659-4b11-c7b6-d808945d8958"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "Lr.fit(x_train,y_train)\n",
    "\n",
    "predicted = Lr.predict(x_test)\n",
    "\n",
    "accuracy3 = accuracy_score(y_test,predicted)\n",
    "precision3 = precision_score(y_test,predicted)\n",
    "recall3 = recall_score(y_test,predicted)\n",
    "f1_3 = f1_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy3,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3933c5",
   "metadata": {
    "id": "6c3933c5"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38cc23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b38cc23",
    "outputId": "4233d6e2-a025-4dbc-a9f5-a4e310288218"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "k-NN Classifier\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors = 50, metric = 'minkowski', p = 1)\n",
    "\n",
    "kNN.fit(x_train,y_train)\n",
    "\n",
    "predicted = kNN.predict(x_test)\n",
    "accuracy4 = accuracy_score(y_test,predicted)\n",
    "precision4 = precision_score(y_test,predicted)\n",
    "recall4 = recall_score(y_test,predicted)\n",
    "f1_4 = f1_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy4,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116900a8",
   "metadata": {
    "id": "116900a8"
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c64618",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14c64618",
    "outputId": "7cb01a0b-e79a-420f-d22a-d889326193ea"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Naive Bayes Classifier\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB.fit(x_train,y_train)\n",
    "\n",
    "predicted = NB.predict(x_test)\n",
    "accuracy5 = accuracy_score(y_test,predicted)\n",
    "precision5 = precision_score(y_test,predicted)\n",
    "recall5 = recall_score(y_test,predicted)\n",
    "f1_5 = f1_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy5,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f980f",
   "metadata": {
    "id": "501f980f"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d80581",
   "metadata": {
    "id": "60d80581"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# SVM Classifier\n",
    "\n",
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# # Create a SVM classifier with RBF kernel\n",
    "# svm = SVC(kernel='rbf',random_state=88)\n",
    "\n",
    "# # Train the classifier using the training data\n",
    "# svm.fit(x_train,y_train)\n",
    "\n",
    "# predicted = svm.predict(x_test)\n",
    "# accuracy = accuracy_score(y_test,predicted)\n",
    "# precision6 = precision_score(y_test,predicted)\n",
    "# recall6 = recall_score(y_test,predicted)\n",
    "# f1_6 = f1_score(y_test,predicted)\n",
    "# print(\"Accuracy:\", accuracy6,\"\\n\")\n",
    "# Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "# Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "# print(Conf_Mat,\"\\n\")\n",
    "# report = classification_report(y_test,predicted)\n",
    "# print(\"Classification report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff18c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01ff18c7",
    "outputId": "c0bb38f3-1be2-4397-f8ba-38a5c6b6b73d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=500),\n",
    "    DecisionTreeClassifier( random_state=88),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_neighbors = 50, metric = 'minkowski', p = 1),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=88)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f4c5d",
   "metadata": {
    "id": "e66f4c5d"
   },
   "source": [
    "### results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d5d02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "ed4d5d02",
    "outputId": "097edba6-9a71-428b-cfb7-8c9a68a4696a"
   },
   "outputs": [],
   "source": [
    "\n",
    "width = 0.2\n",
    "x = np.arange(len(models))\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - 1.5*width, accuracy, width, label='Accuracy')\n",
    "rects2 = ax.bar(x - 0.5*width, precision, width, label='Precision')\n",
    "rects3 = ax.bar(x + 0.5*width, recall, width, label='Recall')\n",
    "rects4 = ax.bar(x + 1.5*width, f1, width, label='F1-score')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "# add spacing between models\n",
    "ax.set_xlim(x[0]-width*2, x[-1]+width*2)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5e8d4",
   "metadata": {
    "id": "97c5e8d4"
   },
   "source": [
    "Logarithme scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359193f",
   "metadata": {
    "id": "e359193f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3d6983",
   "metadata": {
    "id": "cd3d6983"
   },
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108be5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "id": "e108be5e",
    "outputId": "60564d12-c347-4380-9235-c02c91459da7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    " \n",
    "train=pd.DataFrame(scaler.fit_transform(train),\n",
    "            columns=train.columns, index=train.index) \n",
    "\n",
    "test=pd.DataFrame(scaler.transform(test),\n",
    "            columns=test.columns, index=test.index) \n",
    "\n",
    "\n",
    "y_train = train.iloc[:, -1]  # select the last column (label) as y_train\n",
    "x_train = train.iloc[:, :-1]  # select all columns except the last one as x_train\n",
    "\n",
    "y_test = test.iloc[:, -1]  # select the last column (label) as y_test\n",
    "x_test = test.iloc[:, :-1]  # select all columns except the last one as x_test\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b4f51",
   "metadata": {
    "id": "311b4f51"
   },
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91f52f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f91f52f",
    "outputId": "a5badc71-4137-4a71-f1cb-3873cbba50f0"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier( random_state=88)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "predicted = dt.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy1 = accuracy_score(y_test,predicted)\n",
    "precision1 = precision_score(y_test,predicted)                 \n",
    "recall1 = recall_score(y_test,predicted)\n",
    "f1_1 = f1_score(y_test,predicted)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy1,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875003c",
   "metadata": {
    "id": "4875003c"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86df5f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "e86df5f6",
    "outputId": "464ec5a4-3933-427f-b6eb-b99305964b4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# print the classification report\n",
    "cr = classification_report(y_test, predicted)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb272fae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "fb272fae",
    "outputId": "8133b54e-1471-41c7-f52e-f9eca2259f5a"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt, feature_names=x_train.columns, class_names=['0','1'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OgyXYvmPz4yT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgyXYvmPz4yT",
    "outputId": "7765a9a4-98e0-4492-ddef-5d2d75131181"
   },
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f3f8c",
   "metadata": {
    "id": "dd0f3f8c"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "dot_data=export_graphviz(dt,out_file='tree.dot',feature_names=x_train.columns,filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913c364",
   "metadata": {
    "id": "6913c364"
   },
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237abba6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "237abba6",
    "outputId": "d602b9ff-35ac-4d3e-9f9b-4b1175ece346"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# Fit the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=88)\n",
    "model.fit(x_train, y_train)\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy2 = accuracy_score(y_test,y_pred)\n",
    "precision2 = precision_score(y_test,y_pred)\n",
    "recall2 = recall_score(y_test,y_pred)\n",
    "f1_2 = f1_score(y_test,y_pred)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy score: \", accuracy2)\n",
    "print(\"Confusion matrix: \\n\", conf_mat)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35031745",
   "metadata": {
    "id": "35031745"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ee3f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "808ee3f7",
    "outputId": "3e8578b9-bc2c-4815-93b5-8c1ee08fe426"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "Lr.fit(x_train,y_train)\n",
    "\n",
    "predicted = Lr.predict(x_test)\n",
    "\n",
    "accuracy3 = accuracy_score(y_test,predicted)\n",
    "precision3 = precision_score(y_test,predicted)\n",
    "recall3 = recall_score(y_test,predicted)\n",
    "f1_3 = f1_score(y_test,predicted)\n",
    "\n",
    "print(\"Accuracy:\", accuracy3,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68321e03",
   "metadata": {
    "id": "68321e03"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca6d31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61ca6d31",
    "outputId": "67f34a82-067f-4ec4-b6e9-f517de6c62a5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "k-NN Classifier\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors = 50, metric = 'minkowski', p = 1)\n",
    "\n",
    "kNN.fit(x_train,y_train)\n",
    "\n",
    "predicted = kNN.predict(x_test)\n",
    "accuracy4 = accuracy_score(y_test,predicted)\n",
    "precision4 = precision_score(y_test,predicted)\n",
    "recall4 = recall_score(y_test,predicted)\n",
    "f1_4 = f1_score(y_test,predicted)\n",
    "\n",
    "print(\"Accuracy:\", accuracy4,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b382dce",
   "metadata": {
    "id": "3b382dce"
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2323c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80f2323c",
    "outputId": "0e5e78f7-4a11-4728-cb88-cace50a1e19d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Naive Bayes Classifier\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB.fit(x_train,y_train)\n",
    "\n",
    "predicted = NB.predict(x_test)\n",
    "\n",
    "accuracy5 = accuracy_score(y_test,predicted)\n",
    "precision5 = precision_score(y_test,predicted)\n",
    "recall5 = recall_score(y_test,predicted)\n",
    "f1_5 = f1_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy5,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38f33c",
   "metadata": {
    "id": "ae38f33c"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa8fff",
   "metadata": {
    "id": "6eaa8fff"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# SVM Classifier\n",
    "\n",
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# # Create a SVM classifier with RBF kernel\n",
    "# svm = SVC(kernel='rbf',random_state=88)\n",
    "\n",
    "# # Train the classifier using the training data\n",
    "# svm.fit(x_train,y_train)\n",
    "\n",
    "# predicted = svm.predict(x_test)\n",
    "# accuracy = accuracy_score(y_test,predicted)\n",
    "# precision6 = precision_score(y_test,predicted)\n",
    "# recall6 = recall_score(y_test,predicted)\n",
    "# f1_6 = f1_score(y_test,predicted)\n",
    "# print(\"Accuracy:\", accuracy6,\"\\n\")\n",
    "# Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "# Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "# print(Conf_Mat,\"\\n\")\n",
    "# report = classification_report(y_test,predicted)\n",
    "# print(\"Classification report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b448c1",
   "metadata": {
    "id": "90b448c1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fff6f93",
   "metadata": {
    "id": "4fff6f93"
   },
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e2aa4",
   "metadata": {
    "id": "9d2e2aa4"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5a55f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76a5a55f",
    "outputId": "d6ca8b78-b9bb-4085-ead1-ec69427efbae"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=500),\n",
    "    DecisionTreeClassifier(random_state=88),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_neighbors = 50, metric = 'minkowski', p = 1),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=88)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5aa00a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "0d5aa00a",
    "outputId": "81e9a68d-1b63-4ba1-b509-93395b29b425"
   },
   "outputs": [],
   "source": [
    "width = 0.2\n",
    "x = np.arange(len(models))\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - 1.5*width, accuracy, width, label='Accuracy')\n",
    "rects2 = ax.bar(x - 0.5*width, precision, width, label='Precision')\n",
    "rects3 = ax.bar(x + 0.5*width, recall, width, label='Recall')\n",
    "rects4 = ax.bar(x + 1.5*width, f1, width, label='F1-score')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "# add spacing between models\n",
    "ax.set_xlim(x[0]-width*2, x[-1]+width*2)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813be15",
   "metadata": {
    "id": "a813be15"
   },
   "source": [
    "# features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86e753",
   "metadata": {
    "id": "6d86e753"
   },
   "source": [
    "## RandomForestClassifier feature selection+Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c98e6",
   "metadata": {
    "id": "d47c98e6"
   },
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578fab2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9578fab2",
    "outputId": "7c32b4bf-976b-474a-8ff4-187b7634ce6c"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# Import the required libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of the Random Forest Classifier\n",
    "sel =SelectFromModel(RandomForestClassifier(n_estimators=100,random_state=88))\n",
    "\n",
    "# Train the classifier using the training set\n",
    "sel.fit(x_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "sel.get_support()\n",
    "# Sort the features based on their importances in descending order\n",
    "selected_fet=x_train.columns[(sel.get_support())]\n",
    "\n",
    "print('nbr of features selected  ',len(selected_fet))\n",
    "\n",
    "print(' features selected  ',selected_fet)\n",
    "\n",
    "\n",
    "\n",
    "# Train a new classifier using only the selected features\n",
    "rf_new = RandomForestClassifier(n_estimators=100)\n",
    "rf_new.fit(x_train.loc[:, selected_fet], y_train)\n",
    "\n",
    "# Test the new classifier using the testing set and evaluate its performance\n",
    "y_pred = rf_new.predict(x_test.loc[:, selected_fet])\n",
    "score = rf_new.score(x_test.loc[:, selected_fet], y_test)\n",
    "print(\"Accuracy score: \", score)\n",
    "\n",
    "\n",
    "Conf_Mat = confusion_matrix(y_test,y_pred)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f71761d",
   "metadata": {
    "id": "3f71761d"
   },
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f9f1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a7f9f1a",
    "outputId": "15711322-16e6-4aa0-8d36-6a111bdc3dbe"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "Lr.fit(x_train.loc[:, selected_fet], y_train)\n",
    "\n",
    "predicted = Lr.predict(x_test.loc[:, selected_fet])\n",
    "\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6441a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6a6441a",
    "outputId": "274dfbef-c475-43b1-f4ee-82bc358d4e70"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=500),\n",
    "    RandomForestClassifier(n_estimators=100,random_state=88)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(x_train.loc[:, selected_fet], y_train)\n",
    "    y_pred = model.predict(x_test.loc[:, selected_fet])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s90U-3qP4eBo",
   "metadata": {
    "id": "s90U-3qP4eBo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tjTvsMfb4Y25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "tjTvsMfb4Y25",
    "outputId": "41e7bcf5-e1f4-4ace-ea78-a5178ac36e4f"
   },
   "outputs": [],
   "source": [
    "width = 0.2\n",
    "x = np.arange(len(models))\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - 1.5*width, accuracy, width, label='Accuracy')\n",
    "rects2 = ax.bar(x - 0.5*width, precision, width, label='Precision')\n",
    "rects3 = ax.bar(x + 0.5*width, recall, width, label='Recall')\n",
    "rects4 = ax.bar(x + 1.5*width, f1, width, label='F1-score')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "# add spacing between models\n",
    "ax.set_xlim(x[0]-width*2, x[-1]+width*2)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe93971",
   "metadata": {
    "id": "7fe93971"
   },
   "source": [
    "## RFEClassifier feature selection+Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fdab3f",
   "metadata": {
    "id": "38fdab3f"
   },
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa3d6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "58aa3d6d",
    "outputId": "1df5e317-755a-4561-afe6-d47e7bdf30d6"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an instance of the estimator (DecisionTreeClassifier)\n",
    "estimator = DecisionTreeClassifier(random_state=88)\n",
    "\n",
    "# Create an instance of the feature selector (RFE)\n",
    "selector = RFE(estimator)  # Select features\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "# Transform the training and testing data using the selected features\n",
    "x_train_selected = selector.transform(x_train)\n",
    "x_test_selected = selector.transform(x_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model = DecisionTreeClassifier(random_state=88)\n",
    "model.fit(x_train_selected, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(x_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "Conf_Mat = confusion_matrix(y_test, y_pred)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat, index=['Actual DOS', 'Actual Not DOS'], columns=['Predicted DOS', 'Predicted Not DOS'])\n",
    "print(Conf_Mat)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "# Calculate the predicted probabilities\n",
    "y_prob = model.predict_proba(x_test_selected)\n",
    "y_prob = y_prob[:, 1]\n",
    "\n",
    "# Calculate the False Positive Rate (FPR) and True Positive Rate (TPR) for the ROC curve\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(FPR, TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "roc_auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(roc_auc_score)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe6159",
   "metadata": {
    "id": "ecbe6159"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038ca42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "6038ca42",
    "outputId": "267e10f6-7705-411d-b70d-e22866e9bd0c"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create an instance of the estimator (DecisionTreeClassifier)\n",
    "estimator = DecisionTreeClassifier(random_state=88)\n",
    "\n",
    "# Create an instance of the feature selector (RFE)\n",
    "selector = RFE(estimator)  # Select features\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "# Transform the training and testing data using the selected features\n",
    "x_train_selected = selector.transform(x_train)\n",
    "x_test_selected = selector.transform(x_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model = RandomForestClassifier(n_estimators =100)\n",
    "model.fit(x_train_selected, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(x_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "Conf_Mat = confusion_matrix(y_test, y_pred)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat, index=['Actual DOS', 'Actual Not DOS'], columns=['Predicted DOS', 'Predicted Not DOS'])\n",
    "print(Conf_Mat)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "# Calculate the predicted probabilities\n",
    "y_prob = model.predict_proba(x_test_selected)\n",
    "y_prob = y_prob[:, 1]\n",
    "\n",
    "# Calculate the False Positive Rate (FPR) and True Positive Rate (TPR) for the ROC curve\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(FPR, TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "roc_auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(roc_auc_score)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bac0c0",
   "metadata": {
    "id": "66bac0c0"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431f23a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "7431f23a",
    "outputId": "a7f42fc8-9c92-4eaf-9264-e2d160d914c8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create an instance of the estimator (DecisionTreeClassifier)\n",
    "estimator = DecisionTreeClassifier(random_state=88)\n",
    "\n",
    "# Create an instance of the feature selector (RFE)\n",
    "selector = RFE(estimator)  # Select features\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(x_train, y_train)\n",
    "\n",
    "# Transform the training and testing data using the selected features\n",
    "x_train_selected = selector.transform(x_train)\n",
    "x_test_selected = selector.transform(x_test)\n",
    "\n",
    "# Train the model on the selected features\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_selected, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(x_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "Conf_Mat = confusion_matrix(y_test, y_pred)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat, index=['Actual DOS', 'Actual Not DOS'], columns=['Predicted DOS', 'Predicted Not DOS'])\n",
    "print(Conf_Mat)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "# Calculate the predicted probabilities\n",
    "y_prob = model.predict_proba(x_test_selected)\n",
    "y_prob = y_prob[:, 1]\n",
    "\n",
    "# Calculate the False Positive Rate (FPR) and True Positive Rate (TPR) for the ROC curve\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(FPR, TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "roc_auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(roc_auc_score)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76febdf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76febdf1",
    "outputId": "40c994e9-0692-4f76-f111-ac36567d7799"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=500),\n",
    "    DecisionTreeClassifier(random_state=88),\n",
    "    RandomForestClassifier(n_estimators =100)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(x_train_selected, y_train)\n",
    "    y_pred = model.predict(x_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc-8I6yn5Fak",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "bc-8I6yn5Fak",
    "outputId": "cf25369b-8639-45c3-fcd5-a3eeb7a54ee2"
   },
   "outputs": [],
   "source": [
    "width = 0.2\n",
    "x = np.arange(len(models))\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - 1.5*width, accuracy, width, label='Accuracy')\n",
    "rects2 = ax.bar(x - 0.5*width, precision, width, label='Precision')\n",
    "rects3 = ax.bar(x + 0.5*width, recall, width, label='Recall')\n",
    "rects4 = ax.bar(x + 1.5*width, f1, width, label='F1-score')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "# add spacing between models\n",
    "ax.set_xlim(x[0]-width*2, x[-1]+width*2)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a9bc1",
   "metadata": {
    "id": "af9a9bc1"
   },
   "source": [
    "# CFS(mutual_info_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5295c26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "e5295c26",
    "outputId": "154332f9-b2b2-4efa-df88-7bd9404c6d45"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_info = mutual_info_classif(x_train, y_train)\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = x_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3cc4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00f3cc4d",
    "outputId": "57e3e43e-3606-410b-ca5b-f08bcf80dcf7"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "\n",
    "# Feature selection using CFS\n",
    "selector = SelectKBest(mutual_info_classif, k=40)\n",
    "X_train_new = selector.fit_transform(x_train, y_train)\n",
    "X_test_new = selector.transform(x_test)\n",
    "\n",
    "# Get indices of selected features\n",
    "selected_features_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Print selected features\n",
    "selected_features = train.columns[selected_features_indices]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a52521",
   "metadata": {
    "id": "96a52521"
   },
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03b16d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "bd03b16d",
    "outputId": "6d45b31e-ae64-4e7e-a68c-da07f46d70c9"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "\n",
    "dt.fit(X_train_new, y_train)\n",
    "\n",
    "predicted = dt.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "\n",
    "\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_prob = dt.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44578b5b",
   "metadata": {
    "id": "44578b5b"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861016c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "d861016c",
    "outputId": "fed1bdde-cd6d-497e-bfab-714832bdbdc8"
   },
   "outputs": [],
   "source": [
    "Rf =  RandomForestClassifier(n_estimators =100)\n",
    "Rf.fit(X_train_new, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predicted = Rf.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "\n",
    "\n",
    "y_prob = Rf.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10caf23",
   "metadata": {
    "id": "d10caf23"
   },
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314da83a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "314da83a",
    "outputId": "7307d5f7-2b4b-45a5-87ac-dc4d11931aa2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "Lr.fit(X_train_new,y_train)\n",
    "\n",
    "predicted = Lr.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "\n",
    "\n",
    "y_prob = Lr.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35579b",
   "metadata": {
    "id": "4f35579b"
   },
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c37b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "1b8c37b9",
    "outputId": "a676bd62-f5db-4b06-9333-9afbf8322a97"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "k-NN Classifier\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors = 50, metric = 'minkowski', p = 1)\n",
    "\n",
    "kNN.fit(X_train_new,y_train)\n",
    "\n",
    "predicted = kNN.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "y_prob = kNN.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11826467",
   "metadata": {
    "id": "11826467"
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d6b92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "f44d6b92",
    "outputId": "40dfdf72-85e8-4de8-9616-35dce580f6ff"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Naive Bayes Classifier\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB.fit(X_train_new,y_train)\n",
    "\n",
    "predicted = NB.predict(X_test_new)\n",
    "\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "y_prob = NB.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ac43d",
   "metadata": {
    "id": "0c5ac43d"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea2c7c",
   "metadata": {
    "id": "82ea2c7c"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# SVM Classifier\n",
    "\n",
    "# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# # Create a SVM classifier with RBF kernel\n",
    "# svm = SVC(kernel='rbf',random_state=88)\n",
    "\n",
    "# # Train the classifier using the training data\n",
    "# svm.fit(X_train_new, y_train)\n",
    "\n",
    "# predicted = svm.predict(X_test_new)\n",
    "# accuracy = accuracy_score(y_test,predicted)\n",
    "# print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "# Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "# Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "# print(Conf_Mat,\"\\n\")\n",
    "# report = classification_report(y_test,predicted)\n",
    "# print(\"Classification report:\\n\", report)\n",
    "\n",
    "# y_prob = NB.predict_proba(X_test_new)\n",
    "\n",
    "# y_prob = y_prob[:,1]\n",
    "\n",
    "# FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# plt.plot(FPR,TPR)\n",
    "# plt.xlabel('FPR')\n",
    "# plt.ylabel('TPR')\n",
    "# plt.show()\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "# print(roc_auc_score)\n",
    "# # Calculate the confusion matrix\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# # Calculate the false alarm rate\n",
    "# false_alarm_rate = fp / (fp + tn)\n",
    "# print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77596a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a77596a",
    "outputId": "93f0bb3a-9387-4bce-881f-6b1b2bd25180"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=500),\n",
    "    DecisionTreeClassifier(random_state=88),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_neighbors = 50, metric = 'minkowski', p = 1),\n",
    "    RandomForestClassifier(n_estimators =100)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(X_train_new, y_train)\n",
    "    y_pred = model.predict(X_test_new)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72e744",
   "metadata": {
    "id": "7c72e744"
   },
   "source": [
    "# Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab991f29",
   "metadata": {
    "id": "ab991f29"
   },
   "source": [
    "### chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d02fad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "82d02fad",
    "outputId": "f843c7c8-fb40-4888-872b-6ff4f627a444"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "chi_scores, p_values = chi2(x_train, y_train)\n",
    "chi_scores = pd.Series(chi_scores)\n",
    "p_values = pd.Series(p_values)\n",
    "chi_scores.index = p_values.index = x_train.columns\n",
    "chi_scores.sort_values(ascending=False)\n",
    "chi_scores.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c509538",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c509538",
    "outputId": "a5a870c2-f94f-4bb0-d286-6e999abfa8e2"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Feature extraction\n",
    "selector = SelectKBest(score_func=chi2, k=13)\n",
    "X_train_new = selector.fit_transform(x_train, y_train)\n",
    "X_test_new = selector.transform(x_test)\n",
    "# Get indices of selected features\n",
    "selected_features_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Print selected features\n",
    "selected_features = train.columns[selected_features_indices]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f17844",
   "metadata": {
    "id": "54f17844"
   },
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c65e19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "b3c65e19",
    "outputId": "264df5c2-6b83-4edf-943a-c9d4180a03d2"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=88)\n",
    "dt.fit(X_train_new, y_train)\n",
    "predicted = dt.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_prob = dt.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc458bc",
   "metadata": {
    "id": "0cc458bc"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4005b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "9d4005b6",
    "outputId": "bf317dd8-4db5-4588-8fa0-984c7e672bfd"
   },
   "outputs": [],
   "source": [
    "Rf =  RandomForestClassifier(n_estimators =1000,max_depth=40,random_state=88)\n",
    "Rf.fit(X_train_new, y_train)\n",
    "\n",
    "\n",
    "\n",
    "predicted = Rf.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "\n",
    "\n",
    "y_prob = Rf.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd4fad",
   "metadata": {
    "id": "27fd4fad"
   },
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8a35b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "id": "1ea8a35b",
    "outputId": "28558a5a-4878-464e-a0d2-6f83d8bbe79a"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lr = LogisticRegression()\n",
    "\n",
    "Lr.fit(X_train_new,y_train)\n",
    "\n",
    "predicted = Lr.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predicted)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predicted)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "\n",
    "\n",
    "y_prob = Lr.predict_proba(X_test_new)\n",
    "\n",
    "y_prob = y_prob[:,1]\n",
    "\n",
    "FPR, TPR, Thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(FPR,TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score = roc_auc_score(y_test,y_prob)\n",
    "print(roc_auc_score)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predicted).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207ee19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e207ee19",
    "outputId": "c1bd9200-91d9-4a58-d86e-37064bd98a82"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=500),\n",
    "    DecisionTreeClassifier(random_state=88),\n",
    "    RandomForestClassifier(n_estimators =1000,max_depth=40,random_state=88)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(X_train_new , y_train)\n",
    "    y_pred = model.predict(X_test_new )\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da4d91",
   "metadata": {
    "id": "86da4d91"
   },
   "source": [
    "# features selection using Pearson's correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7cf38",
   "metadata": {
    "id": "29f7cf38"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cfe5e8f",
   "metadata": {
    "id": "1cfe5e8f"
   },
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1038c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca1038c5",
    "outputId": "a6e127d7-cea2-42bd-e5c7-6105ff8816ee"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n",
    "# Define the number of features to select\n",
    "k = 5\n",
    "\n",
    "# Select k best features based on Pearson's correlation coefficient\n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "X_new = selector.fit_transform(x_train, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Create a new dataset with the selected features\n",
    "X_selected = x_train.iloc[:, selected_features]\n",
    "\n",
    "# Train the decision tree on the selected features\n",
    "tree_model = DecisionTreeClassifier(random_state=88)\n",
    "tree_model.fit(X_selected, y_train)\n",
    "\n",
    "# Predict the target variable using the trained model\n",
    "predictions = tree_model.predict(x_test.iloc[:, selected_features])\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predictions)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predictions)\n",
    "print(\"Classification report:\\n\", report)\n",
    "\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee12e6d",
   "metadata": {
    "id": "9ee12e6d"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe5b1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8fe5b1b",
    "outputId": "fffd3a85-189f-4422-fdf5-e345580f2aed"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of features to select\n",
    "k = 5\n",
    "\n",
    "# Select k best features based on Pearson's correlation coefficient\n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "X_new = selector.fit_transform(x_train, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Create a new dataset with the selected features\n",
    "X_selected = x_train.iloc[:, selected_features]\n",
    "\n",
    "# Train the Random Forest on the selected features\n",
    "rf_model = RandomForestClassifier(n_estimators=110, max_depth = 30, random_state=88)\n",
    "rf_model.fit(X_selected, y_train)\n",
    "\n",
    "# Predict the target variable using the trained model\n",
    "predictions = rf_model.predict(x_test.iloc[:, selected_features])\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predictions)\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predictions)\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0b625",
   "metadata": {
    "id": "34a0b625"
   },
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8b145",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8af8b145",
    "outputId": "92b7ebb7-ae8d-447f-d3a8-993581918e37"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of features to select\n",
    "k = 5\n",
    "\n",
    "# Select k best features based on Pearson's correlation coefficient\n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "X_new = selector.fit_transform(x_train, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Create a new dataset with the selected features\n",
    "X_selected = x_train.iloc[:, selected_features]\n",
    "\n",
    "# Train the logistic regression model on the selected features\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_selected, y_train)\n",
    "\n",
    "# Predict the target variable using the trained model\n",
    "predictions = lr_model.predict(x_test.iloc[:, selected_features])\n",
    "accuracy = accuracy_score(y_test,predictions )\n",
    "print(\"Accuracy:\", accuracy,\"\\n\")\n",
    "Conf_Mat = confusion_matrix(y_test,predictions )\n",
    "Conf_Mat = pd.DataFrame(Conf_Mat,index=['Actual DOS','Actual Not DOS'],columns=['Predicted DOS','Predicted Not DOS'])\n",
    "\n",
    "print(Conf_Mat,\"\\n\")\n",
    "report = classification_report(y_test,predictions )\n",
    "print(\"Classification report:\\n\", report)\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "# Calculate the false alarm rate\n",
    "false_alarm_rate = fp / (fp + tn)\n",
    "print('False Alarm Rate:', false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d630a0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d630a0a",
    "outputId": "f89b4ed0-96c3-4201-ac85-ef5598c781b7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 1: Define list of models\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(random_state=88),\n",
    "    RandomForestClassifier(n_estimators=110, max_depth = 30, random_state=88)\n",
    "]\n",
    "\n",
    "# Step 2: Define dictionary to store evaluation metrics\n",
    "eval_metrics = {}\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Evaluate each model\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    model.fit(x_train.iloc[:, selected_features], y_train)\n",
    "    y_pred = model.predict(x_test.iloc[:, selected_features])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    eval_metrics[model_name] = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Step 5: Convert dictionary to dataframe\n",
    "df = pd.DataFrame(eval_metrics, index=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "\n",
    "# Step 6: Return dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2563fac",
   "metadata": {
    "id": "a2563fac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2164581",
   "metadata": {
    "id": "d2164581"
   },
   "source": [
    "comparing the two algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2680f",
   "metadata": {
    "id": "3ed2680f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283abca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "b283abca",
    "outputId": "321c6b0c-e955-4cef-9dbc-da79214da4d9"
   },
   "outputs": [],
   "source": [
    "# Plot the comparison graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['Decision Tree', 'Random Forest']\n",
    "accuracies = [accuracy1, accuracy2]\n",
    "\n",
    "plt.bar(models, accuracies)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Comparison of Decision Tree and Random Forest on NSL-KDD dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745e29b",
   "metadata": {
    "id": "9745e29b"
   },
   "source": [
    " ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742edff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "2742edff",
    "outputId": "050a7c48-9bf8-4cd8-c0f1-ad8513fe017d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the scatter plot for actual vs predicted values for Decision Tree\n",
    "plt.scatter(y_test, predicted, color='blue')\n",
    "plt.title('Actual vs Predicted Values (Decision Tree)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# Plot the scatter plot for actual vs predicted values for Random Forest\n",
    "plt.scatter(y_test, y_pred, color='red')\n",
    "plt.title('Actual vs Predicted Values (Random Forest)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657dc6e3",
   "metadata": {
    "id": "657dc6e3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14f48c2f",
   "metadata": {
    "id": "14f48c2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6b0e3f3b",
   "metadata": {
    "id": "6b0e3f3b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
